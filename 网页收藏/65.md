GitHub新项目Deepo：一键安装11项深度学习框架与环境
=================================================

[By 刘晓坤](/users/0437febc-e991-4698-a3e4-e2f3a76a6e2e)2017年12月18日 14:46

> 最近，一项关注于快速构建深度学习环境的 GitHub 项目十分流行，这个名为 Deepo 的项目由一系列 Docker 镜像组成，包含了 TensorFlow、MXNet、Caffe 和 Torch 等 11 个流行的深度学习研究环境。该项目发布一个多月已经有了近 3000 的收藏量，机器之心简要介绍了该项目，更详细的安装步骤请查看原 GitHub 项目。

项目地址：https://github.com/ufoym/deepo

![](https://image.jiqizhixin.com/uploads/wangeditor/7dfcae48-51a7-4f7b-96a4-6956c046a095/4395301.jpg)

因为 Deepo 是一系列 Docker 镜像，所以它要求先安装 Dokcker 客户端与环境。Docker 主要是希望创建可移植软件的轻量容器，并让这些软件可以在任何安装了 Docker 的机器上运行，而不用关心底层操作系统。所以希望利用该项目安装深度学习环境的读者首先需要了解 Docker。

Deepo 是一系列 Docker 镜像，它的主要特征有：

-   允许我们快速配置深度学习环境
-   支持几乎所有常见的深度学习框架
-   支持 GPU 加速（包括 CUDA 和 cuDNN）, 同样在 CPU 中运行良好
-   支持 Linux（CPU 版和 GPU 版）、OS X（CPU 版）、Windows（CPU 版）

Deepo 的 Dockerfile 生成器主要有以下特征：

-   允许使用类似乐高那样的模块自定义环境
-   自动解决依赖项问题

**可用的 Tags**

![](https://image.jiqizhixin.com/uploads/wangeditor/7dfcae48-51a7-4f7b-96a4-6956c046a095/5195702.png)

**快速启动**

**GPU 版**

**
**

-   安装

第一步：安装 Docker 和 nvidia-docker：

Docker：https://docs.docker.com/engine/installation/

nvidia-docker：https://github.com/NVIDIA/nvidia-docker

第二步：使用以下命令行从 Docker Hub 获取 一体式镜像

``` {data-initialized="true" data-gclp-id="0"}
docker pull ufoym/deepo
```

-   用法

现在我们可以尝试使用以下命令：

``` {data-initialized="true" data-gclp-id="1"}
nvidia-docker run --rm ufoym/deepo nvidia-smi
```

这个命令应该能令 Deepo 从 Docker 容器中使用 GPU，如果该命令不起作用，那么可以在 nvidia-docker GitHub 项目中搜索 Issues 部分，上面有很多解决方案。为了获得一个和容器交互的 shell，它不会在我们推出后自动删除，我们需要键入：

``` {data-initialized="true" data-gclp-id="2"}
nvidia-docker run -it ufoym/deepo bash
```

如果我们希望在主机（机器或虚拟环境）和容器间共享数据和配置，那么可以使用 -v 选项：

``` {data-initialized="true" data-gclp-id="3"}
nvidia-docker run -it -v /host/data:/data -v /host/config:/config ufoym/deepo bash
```

该命令会将主机可视的 /host/data 变为容器中的/data，/host/config 作为/config。这种隔离减少了集装箱化试验重写或使用错误数据。

注意有些框架（如 PyTorch）是噢用共享内存以在进程中共享数据，所以如果使用默认的共享内存分区大小，那么容器运行多进程是不够的。因此我们需要使用 nvidi-docker 运行 --ipc=host 或 --shm-size 命令增加共享内存大小。

``` {data-initialized="true" data-gclp-id="4"}
nvidia-docker run -it --ipc=host ufoym/deepo bash
```

**CPU 版**

-   安装

第一步：安装 Docker

第二步：使用以下命令行从 Docker Hub 获取 一体式镜像

``` {data-initialized="true" data-gclp-id="5"}
docker pull ufoym/deepo:cpu
```

-   用法

现在我们能尝试使用以下命令行：

``` {data-initialized="true" data-gclp-id="6"}
docker run -it ufoym/deepo:cpu bash
```

如果我们希望在主机（机器或虚拟环境）和容器间共享数据和配置，那么可以使用 -v 选项：

``` {data-initialized="true" data-gclp-id="7"}
docker run -it -v /host/data:/data -v /host/config:/config ufoym/deepo:cpu bash
```

注意有些框架（如 PyTorch）是噢用共享内存以在进程中共享数据，所以如果使用默认的共享内存分区大小，那么容器运行多进程是不够的。因此我们需要使用 nvidi-docker 运行 --ipc=host 或 --shm-size 命令增加共享内存大小。![](https://image.jiqizhixin.com/uploads/wangeditor/7dfcae48-51a7-4f7b-96a4-6956c046a095/67194微信图片_20170924135925.png)

``` {data-initialized="true" data-gclp-id="8"}
docker run -it --ipc=host ufoym/deepo:cpu bash
```

声明：本文由机器之心编译出品，原文来自GitHub，转载请查看要求，机器之心对于违规侵权者保有法律追诉权。
