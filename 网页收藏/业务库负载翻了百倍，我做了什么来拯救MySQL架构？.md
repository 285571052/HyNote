# 业务库负载翻了百倍，我做了什么来拯救MySQL架构？

问题:
记录回执数据的，简单来说就好比你发送了一条微博，想看看有多少人已读，有多少人留言等。所以这类场景不存在事务，会有数据的密集型写入，会有明确的统计需求。

做法:
目前的统计频率是每7分钟做一次统计，会有几类统计场景，目前基本都是全表扫描级别的查询语句。


一、引入读写分离，优化初见成效

改进:

1. 把主库的统计需求转移到从库端
    转移了读请求的负载，写入压力得到了极大缓解，后来也经过业务方的应用层面的优化，整体的负载情况就相对乐观了：

2. 从应用层面来做数据路由，比如有10个业务：业务1、业务2在第一个节点，业务3、业务5在第二个节点等等，按照这种路由的配置方式来映射数据源，相对可控，更容易扩展


二、引入列式存储，优化统计性能

问题:

随着业务的扩展，统计查询的需求越来越多, 这样一来统计压力变大，导致系统响应降低，从而导致从库的延迟也开始变大。最大的时候延迟有3个小时，按照这种情况，统计的意义其实已经不大了。

1. Redis
2. 索引
    业务的每个统计需求涉及5个SQL，要对每个场景做优化都需要取舍，最后达到的一个初步效果是字段有5个，索引就有3个，而且不太可控的是一旦某个表的数据量太大导致延迟，整个系统的延迟就会变大，从而造成统计需求都整体垮掉，所以添加索引来解决硬统计需求算是心有力而力不足。结论：索引优化效果有限，需要寻求其他可行解决方案
3. 对于写压力，后续可以通过分片的策略来解决，这里的分片策略和我们传统认为的逻辑不同，这是基于应用层面的分片，应用端来做这个数据路由。这样分片对于业务的爆发式增长就很容易扩展了。有了这一层保障之后，业务的统计需求迁移到从库，写压力就能够平滑的对接了，目前来看写压力的空余空间很大，完全可以支撑指数级的压力。结论：业务数据路由在统计压力减缓后再开始改进。
4. 数据仓库方案

三、引入动态调度，解决统计延迟问题

通过引入Infobright方案对已有的统计需求可以做到完美支持，但是随之而来的一个难点就是对于数据的流转如何平滑支持。我们可以设定流转频率，比如10分钟等或者半个小时，但是目前来看，这个是需要额外的脚本或工具来做的。

比如第一个头疼的问题就是全量的同步，第一次同步肯定是全量的，这么多的数据怎么同步到Infobright里面。

第二个问题，也是更为关键的，那就是同步策略是怎么设定的，是否可以支持的更加灵活。

第三个问题是基于现有的增量同步方案，需要在时间字段上添加索引。对于线上的操作而言又是一个巨大的挑战。

第一次全量同步的时候，可以把起始时间给的早一些，这样截止时间是固定的，逻辑上就是全量的。

通过计算当前时间和上一次执行的时间来得到任务可执行的时间。这样脚本就不需要参数了，这是一个动态调度的迭代过程。

四、引入业务路由，平滑支持业务扩容

目前的架构暂时能够支撑密集型数据写入，但是不能够支持指数级别的压力请求，而且存储容量很难以扩展

从我的理解中，业务层面来做数据路由是最好的一种方式，而且从扩展上来说，也更加友好。

- [业务库负载翻了百倍，我做了什么来拯救MySQL架构？][1]

[1]: https://mp.weixin.qq.com/s/qsoE9TSmCyIiuikhphWGig
