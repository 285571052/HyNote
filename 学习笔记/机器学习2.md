<!--toc-->

- [EM算法](#em算法)
	- [从极大似然法说起-一个简单的例子](#从极大似然法说起-一个简单的例子)
	- [从极大似然法说起-一个稍微复杂点的例子-三硬币模型](#从极大似然法说起-一个稍微复杂点的例子-三硬币模型)
	- [EM算法的具体步骤 和 隐变量](#em算法的具体步骤-和-隐变量)
	- [更一般形式的描述](#更一般形式的描述)
	- [EM算法的证明](#em算法的证明)
	- [其他](#其他)
	- [EM算法的应用-高斯混合聚类](#em算法的应用-高斯混合聚类)

<!-- tocstop -->
# EM算法
EM算法(期望最大化算法,Expectation Maximization Algorithm)是一种迭代算法,用于隐变量(hidden variable)的概率模型参数的极大似然估计,或极大后延概率估计。

EM算法由两部组成:
1. E步:求期望
2. M步:求极大值

## 从极大似然法说起-一个简单的例子
假设有一枚硬币,抛出硬币,其为正面的概率为p,已知m次试验的结果$\{x_1,x_2,...,x_m\}$,使用极大似然法估计参数p

一次试验的概率为:$P(x) = p^x\times(1-p)^{1-x}$

似然函数为:
$L(x_1,x_2,\ldots,x_m;p) = \displaystyle{\prod_{i = 1}^m} P(x_i) = p^{\displaystyle{\sum_{i = 1}^m} x_i}\cdot(1-p)^{m - \displaystyle{\sum_{i = 1}^m} x_i}$

则令$\frac{\partial L(x_1,x_2,\ldots,x_m;p)}{\partial p} = 0$
得:$p = \frac{ \displaystyle {\sum_{i = 1}^m} x_i}{m}$

## 从极大似然法说起-一个稍微复杂点的例子-三硬币模型
假设要有3枚硬币,分别记作A,B,C。这些硬币正面出现的概率分别为$\pi,p,q$。进行如下试验:
先抛出硬币A,根据其结果选出硬币B或C,正面选B,反面选C
然后抛出选中的硬币,如果出现正面,记作1,反面记作0

现有m次试验的结果$(Z,Y) = \{(z_1,y_1),(z_2,y_2),\ldots,(z_m,y_m)\}$,
$z_i$表示第i次试验中,抛出硬币A的结果,$y_i$表示第i次试验抛出第二枚硬币的结果,结果正面为1,反面为0
使用极大似然法估计参数$\theta = (\pi, p,q)^T$

一次试验的概率为:$P(y,z|\theta) = \pi^zp^{zy}(1-p)^{z(1-y)} \times (1-\pi)^{1-z}q^{(1-z)y}(1-q)^{(1-z)(1-y)}$

似然函数为:
$L(\theta|Y,Z) = \displaystyle{\prod_{i = 1}^m} P(y_i,z_i|\theta) =  \pi^{\displaystyle {\sum_{i = 1}^m} z_i}p^{\displaystyle {\sum_{i = 1}^m}z_iy_i}(1-p)^{\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)} \times (1-\pi)^{\displaystyle {\sum_{i = 1}^m}(1-z_i)}q^{\displaystyle {\sum_{i = 1}^m}(1-z_i)y_i}(1-q)^{\displaystyle {\sum_{i = 1}^m}(1-z_i)(1-y_i)}$
为简化运算,取对数形式:

$LL(\theta|Y,Z) = \displaystyle{\sum_{i = 1}^m} \ln P(y_i,z_i|\theta) = \bigg (\displaystyle {\sum_{i = 1}^m} z_i\bigg ) \ln \pi +
\bigg (\displaystyle {\sum_{i = 1}^m}z_iy_i\bigg ) \ln p +
\bigg (\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)\bigg ) \ln (1-p) +
\bigg (\displaystyle {\sum_{i = 1}^m}(1-z_i)\bigg ) \ln (1-\pi) +
\bigg (\displaystyle {\sum_{i = 1}^m}(1-z_i)y_i\bigg ) \ln q +
\bigg (\displaystyle {\sum_{i = 1}^m}(1-z_i)(1-y_i)\bigg ) \ln (1-q)$

$\begin{align}
\frac{\partial LL(\theta|Y,Z)}{\partial \theta} &= \begin{bmatrix}
\frac{\partial LL(\theta|Y,Z)}{\partial \pi}  \\
\frac{\partial LL(\theta|Y,Z)}{\partial p}  \\
\frac{\partial LL(\theta|Y,Z)}{\partial q}
\end{bmatrix} \\
&= \begin{bmatrix}
\frac{\displaystyle {\sum_{i = 1}^m} z_i}{\pi} - \frac{\displaystyle{\sum_{i = 1}^m} (1 - z_i)}{1 - \pi}  \\
\frac{\displaystyle {\sum_{i = 1}^m}z_iy_i}{p} - \frac{\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)}{1-p}\\
\frac{\displaystyle {\sum_{i = 1}^m}z_iy_i}{q} - \frac{\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)}{1-q}
\end{bmatrix}
\end{align}$

令$\frac{\partial LL(\theta|Y,Z)}{\partial \theta}=0$
得:
$\pi = \frac{ \displaystyle {\sum_{i = 1}^m} z_i}{m}$
$p = \frac{ \displaystyle {\sum_{i = 1}^m} z_iy_i}{\displaystyle {\sum_{i = 1}^m} z_i}$
$q = \frac{ \displaystyle {\sum_{i = 1}^m}  (1-z_i)y_i}{\displaystyle {\sum_{i = 1}^m} (1-z_i)}$

## EM算法的具体步骤 和 隐变量
原log似然函数:$LL(\theta|Y,Z) = \displaystyle{\sum_{i = 1}^m} \ln P(y_i,z_i|\theta)$
上面的例子中,隐变量或者说中间变量$z_i$是已知的, 但$z_i$如果是未知的,那么我们要怎么进行参数的估计?

按照上面的过程,极大似然法无法进行下去,因为我们并不知道输出的结果$y_i$到底是由B硬币生成的,还是C硬币生成的。

使用极大似然法,在求似然函数的时候,需要知道$y_i$和$z_i$(即样本的生成过程信息),但我们不知道$z_i$到底是多少,所以极大似然法无法进行下去。

那么我们如何避开$z_i$真实值的问题,而使得极大似然法得以进行下去?
一个简单地想法就是使用$z_i$的期望,或者是$z_i$的概率取值来代替真实值。

那么$z_i$的概率分布怎么取?
如果我们知道$\theta$的值,那么我们可以轻易地得到$z_i$的分布,如果我们知道$z_i$的值,那么也可以使用极大似然法直接得到$\theta$的参数估计。

EM算法就是使用通过迭代上面提到的两个步骤来实现参数的估计的。

也就是说EM算法取当前$\theta^{(t)}$下$z_i$的后验概率作为$z_i$的概率分布。(具体表示见后面的表达式。)

~~EM算法的想法就是使用隐变量$z_i$的概率取值来代替$z_i$的真实值(每个取值,以其后验概率作为权重),并且使用 **似然函数的期望** 来代替 **似然函数**~~
~~具体表现为:使用$z_i$的后验概率$P(z_i|y_i,\theta)$,来猜测$z_i$,这样就避开的$z_i$的实际取值为多少。~~
~~具体含义见期望的表达式(关于期望见后面的详细信息)。~~
~~这样就避开的z的真实取值。~~

基于上面规避$z_i$的方法,EM算法还有一个特别的地方,那就是它 极大化 似然函数的期望.而不是 极大化似然函数。

即采用$\theta^{(i+1)} =
\begin{matrix}
argmax \\
\theta
\end{matrix} E_{Z|Y,\theta^{(t)}}\bigg(LL(\theta|Y,Z)\bigg)$
而不是直接$\theta^{(i+1)} =
\begin{matrix}
argmax \\
\theta
\end{matrix} LL(\theta|Y)$

后面证明两者是等价的,我们先看EM算法的具体过程:

$\begin{align}
E_{Z|Y,\theta^{(t)}}\bigg(LL(\theta|Y,Z)\bigg)
& = E_{Z|Y,\theta^{(t)}}\bigg( \displaystyle{\sum_{i = 1}^m} \ln P(y_i,z_i|\theta)\bigg)
\\
&= \displaystyle{\sum_{i = 1}^m}  \displaystyle{\sum_{z = 0}^1}
P(z|y_i,\theta^{(t)})
\ln P(y_i,z|\theta)
\\
&= \displaystyle{\sum_{i = 1}^m}  \displaystyle{\sum_{z = 0}^1}
P(z|y_i,\theta^{(t)})
\bigg(
z \ln \pi +
zy_i \ln p +
z(1-y_i) \ln (1-p) +
(1-z) \ln (1-\pi) +
(1-z)y_i \ln q +
(1-z)(1-y_i) \ln (1-q) \bigg)
\end{align}$

>期望:$E\bigg(\ln\big(g(x)\big)\bigg) = \displaystyle{\sum_z}P(z)\ln\big(g(x)\big)$

因为我们不知道$z_i$到底是多少,因此我们从概率的角度来考虑,我们列举了$z_i$的所有可能值,使用后验概率作为其权重。

~~注意:在EM算法中,$p(z|y_i,\theta^{(t)})$和参数$\theta$有关,但是把$p(z|y_i,\theta^{(t)})$这个量当作一个常量,具体原因见后面EM算法迭代的过程及其证明。我们先继续沿着极大似然法这个思路算下去。~~

为方便,记$P(z|y_i,\theta^{(t)}) = \lambda_{zi}$

令$\frac{\partial E_{Z|Y,\theta^{(t)}}\big(LL(\theta|Y,Z)\big)}{\partial \theta} = 0$
得:
$\pi = \frac{ \displaystyle{\sum_{i = 1}^m}\displaystyle{\sum_{z = 0}^1} z\lambda_{zi}}{\displaystyle{\sum_{i = 1}^m}\displaystyle{\sum_{z = 0}^1} \lambda_{zi}}$

$p = \frac{ \displaystyle{\sum_{i = 1}^m}\displaystyle{\sum_{z = 0}^1} zy_i\lambda_{zi}}{\displaystyle{\sum_{i = 1}^m}\displaystyle{\sum_{z = 0}^1} z\lambda_{zi}}$

$q = \frac{ \displaystyle{\sum_{i = 1}^m}\displaystyle{\sum_{z = 0}^1} (1-z)y_i\lambda_{zi}}{\displaystyle{\sum_{i = 1}^m}\displaystyle{\sum_{z = 0}^1} (1-z)\lambda_{zi}}$

$\lambda_{zi} = P(z|y_i,\theta^{(t)}) = \frac{P(y_i,z|\theta^{(t)})}{ P(y_i|\theta^{(t)})} = \frac{P(y_i,z|\theta^{(t)})}{\displaystyle{\sum_{z_j = 0}^1} P(y_i,z_j|\theta^{(t)})}$

EM算法是一个迭代算法
$\lambda_{zi}$为当前参数$\theta^{(t)}$下$z$的后验概率
上面$\pi,p,q$的等式,则是$\theta^{(i+1)} = \begin{matrix}
argmax\\
\theta
\end{matrix} E_{Z|Y,\theta^{(t)}}\big( LL(\theta|Y,Z) \big)$的解
~~迭代的过程,使用了上一次迭代的结果$\lambda_{zi}$
这也解释了为什么把$\lambda_{zi}$看作常量,因为这个量来自于上一次迭代输出的参数,而和这一次迭代的需要更新的参数无关。~~

我们整理一下这题EM算法的具体过程:
0. 随机取参数$\theta$
1. E步:计算隐变量$\lambda_{zi}$的值
2. M步:更新参数$\theta$
3. 重复2,3步骤,直到满足停止条件

为什么不直接使用z的后验概率展开到似然函数中,而非得大费周章地使用似然函数的期望再展开呢?
直接使用后验概率,它的表达式为:
$L(\theta|Y) = \displaystyle{\prod_{i = 1}^m} P(y_i|\theta) = \displaystyle{\prod_{i = 1}^m}  \displaystyle{\sum_{z = 0}^1}
p(z|y_i,\theta^{(t)})P(y_i,z)$
取对数之后为:$LL(\theta|Y) = \ln \displaystyle{\prod_{i = 1}^m} P(y_i|\theta) = \displaystyle{\sum_{i = 1}^m} \ln \displaystyle{\sum_{z = 0}^1}
p(z|y_i,\theta^{(t)})P(y_i,z)$
而使用似然函数期望对应的表达式为:$E_{Z|Y,\theta^{(t)}}(LL(\theta|Y,Z)) = \displaystyle{\sum_{i = 1}^m}  \displaystyle{\sum_{z = 0}^1}
p(z|y_i,\theta^{(t)})
\ln P(y_i,z)$

无论是没取对数(有连乘),还是取了对数(有$\ln \sum$),其求导运算都不好算,而似然函数的期望,则把$\ln$放在了$\sum$的里面,显然运算更加简单。

## 更一般形式的描述
有样本$Y$,已知每个样本的密度函数均为$P(y,z|\theta)$,估计该密度函数参数的值。
$y$为输出的结果(即样本),$z$为样本生成过程中的中间变量,$\theta$为分布的参数。

由题意,可以得到联合密度(对数形式)为:$LL(\theta|Y,Z) = \displaystyle{\sum_{i}} \ln P(y_i,z_i|\theta)$
因为我们并不知道 $z_i$的值为多少,我们采用$z_i$的概率取值,并且以其后验概率为权重。
我们希望简化运算,因此我们取似然函数的期望:
$\begin{align}
E_{Z|Y,\theta^{(t)}}\big( LL(\theta|Y,Z) \big) &= E_{Z|Y,\theta^{(t)}}\big( \displaystyle{\sum_{i}} \ln P(y_i,z_i|\theta) \big) \\
&= \displaystyle{\sum_i} \displaystyle{\sum_{z}} p(z|y_i,\theta^{(t)})\ln P(y_i,z_i|\theta)
\end{align}$

令$\frac{\partial E_{Z|Y,\theta^{(t)}}\big( LL(\theta|Y,Z) \big)}{\partial \theta} = 0$,得到$\theta$关于$p(z|y_i,\theta^{(t)})$的表达式

至此,EM算法的准备工作完毕,下面进行EM算法的迭代过程:
1. 随机取$\theta$的初始值
2. E步:求似然函数期望的表达式
	 即 计算$z_i$的后验概率 $p(z_i|y_i,\theta^{(t)})$
3. M步:最大化参数
	即 $\theta^{(t + 1)} = \begin{matrix} argmax \\ \theta\end{matrix} E_{Z|Y,\theta^{(t)}}\big( LL(\theta|Y,Z) \big)$
	具体的计算就是上面,对应参数的导数为0求解。

4. 重复2,3步骤,直到达到停止条件
		停止条件可以是达到最大轮迭代数,期望变化,参数变化达到阈值
		$|\theta^{(t+1)} - \theta^{(t)}| < \epsilon_1$ 或$\bigg|E_{Z|Y,\theta^{(t)}}\big( LL(\theta^{(t+1)}|Y,Z) \big) - E_{Z|Y,\theta^{(t)}}\big( LL(\theta^{(t)}|Y,Z) \big)\bigg|< \epsilon_2$

至此,就可以得到参数的估计值了。

## EM算法的证明
为什么EM算法这样迭代是有效的?
$\begin{align}LL(\theta|Y) = \ln P(Y|\theta) &= \frac{\ln P(Y,Z|\theta)}{\ln P(Z|Y,\theta)} &,贝叶斯定理\\\\
&= \ln P(Y,Z|\theta) - \ln P(Z|,Y\theta) \\\\
&= \displaystyle{\sum_z}P(Z|Y,\theta^{(t)})\ln P(Y,Z|\theta) - \displaystyle{\sum_z}P(Z|Y,\theta^{(t)})\ln P(Z|,Y\theta)
&, \displaystyle{\sum_z}P(Z|Y,\theta^{(t)}) = 1\\\\
&= Q(\theta|\theta^{t}) +  H(\theta|\theta^{t})&,为方便,定义两个符号
\end{align}$

令$\theta = \theta^{(t)}$
有$\ln P(Y|\theta^{(t)}) = Q(\theta^{(t)}|\theta^{(t)}) +  H(\theta^{(t)}|\theta^{(t)})$

则上面两个方程式相减有:
$\begin{align}\ln P(Y|\theta) - \ln P(Y|\theta^{(t))}) &= \bigg (Q(\theta|\theta^{t})  - Q(\theta^{t}|\theta^{t}) \bigg) + \bigg(H(\theta|\theta^{t})  - H(\theta^{t}|\theta^{t})\bigg) \\
&\geq \bigg(H(\theta|\theta^{t})  - H(\theta^{t}|\theta^{t})\bigg) \\
&\geq 0
\end{align}$

也就是说,EM算法迭代之后,Q的值要么增大,要么不变(不变则说明迭代结束),所以EM算法是有效的。

证明:$Q(\theta|\theta^{t})  - Q(\theta^{t}|\theta^{t}) \geq 0$
$\theta^{(i+1)} =
\begin{matrix}
argmax \\
\theta
\end{matrix} Q(\theta|\theta^{t})$
也就是说$Q(\theta^{(i+1)}|\theta^{t}) = \max_\theta(Q(\theta|\theta^{t})) \geq Q(\theta^{t}|\theta^{t})$

证明:$H(\theta|\theta^{t})  - H(\theta^{t}|\theta^{t}) \geq 0$
$H(\theta|\theta^{t}) = - \displaystyle{\sum_z}P(Z|Y,\theta^{(t)})\ln P(Z|,Y,\theta)$
由吉布斯不等式(**gibbs' inequality**),$\bigg(H(\theta|\theta^{t})  - H(\theta^{t}|\theta^{t})\bigg) \geq 0$,

>吉布斯不等式(**gibbs' inequality**)
若$\displaystyle{\sum_i} p_i = \displaystyle{\sum_i} q_i = 1,且p_i,q_i \in (0,1],则 -\displaystyle{\sum_i} p_i\ln p_i \leq -\displaystyle{\sum_i} p_i = q_i $,当且仅当$p_i = q_i$时等式成立


## 其他
EM算法可能走到鞍点,故需要多次进行

EM算法实际上有两种:
1. soft EM
		也就是前面我们用的,枚举所有的z,以其后验概率作为每个z的权重,综合考虑

2. hard EM
		$z_i$未知,则取$z_i$的期望作为真实值的近似。(对于离散型不可用,因为期望这个值不一定在可选范围内,比如前面的例子,可选择的值只有0和1,而期望则不是0或者1)

em算法有三个关键的地方:
1. 使用Z的概率取值来代替Z的真实值,这样就避免了Z真实值的需求
2. 极大化 似然函数的期望 而不是极大化似然函数
3. 通过迭代来求解参数

为什么使用后验概率?有没有其他更好的概率分布代替?

## EM算法的应用-高斯混合聚类
