<!--toc-->

- [EM算法](#em算法)
	- [从极大似然法说起-一个简单的例子](#从极大似然法说起-一个简单的例子)
	- [从极大似然法说起-一个稍微复杂点的例子-三硬币模型](#从极大似然法说起-一个稍微复杂点的例子-三硬币模型)
	- [隐变量](#隐变量)
		- [期望](#期望)
	- [EM算法的证明](#em算法的证明)
	- [EM算法的应用-高斯混合聚类](#em算法的应用-高斯混合聚类)

<!-- tocstop -->
# EM算法
EM算法(期望最大化算法,Expectation Maximization Algorithm)是一种迭代算法,用于隐变量(hidden variable)的概率模型参数的极大似然估计,或极大后延概率估计。

EM算法由两部组成:
1. E步
    求期望
2. M步
    求极大值

## 从极大似然法说起-一个简单的例子
假设有一枚硬币,抛出硬币,其为正面的概率为p,已知m次试验的结果$\{x_1,x_2,...,x_m\}$,使用极大似然法估计参数p

一次试验的概率为:$P(x) = p^x\times(1-p)^{1-x}$

似然函数为:
$L(x_1,x_2,\ldots,x_m;p) = \displaystyle{\prod_{i = 1}^m} P(x_i) = p^{\displaystyle{\sum_{i = 1}^m} x_i}\cdot(1-p)^{m - \displaystyle{\sum_{i = 1}^m} x_i}$

则令$\frac{\partial L(x_1,x_2,\ldots,x_m)}{\partial p} = 0$
得:$p = \frac{ \displaystyle {\sum_{i = 1}^m} x_i}{m}$

## 从极大似然法说起-一个稍微复杂点的例子-三硬币模型
假设要有3枚硬币,分别记作A,B,C。这些硬币正面出现的概率分别为$\pi,p,q$。进行如下试验:
先抛出硬币A,根据其结果选出硬币B或C,正面选B,反面选C
然后抛出险种的硬币,如果出现正面,记作1,反面记作0

现有m次试验的结果$D = \{(z_1,y_1),(z_2,y_2),\ldots,(z_m,y_m)\}$,
$z_i$表示第i次试验中,抛出硬币A的结果,$y_i$表示第i次试验抛出第二枚硬币的结果,结果正面为1,反面为0
使用极大似然法估计参数$\theta = (\pi, p,q)^T$

一次试验的概率为:$P(y,z) = \pi^zp^{zy}(1-p)^{z(1-y)} \times (1-\pi)^{1-z}q^{(1-z)y}(1-q)^{(1-z)(1-y)}$

似然函数为:
$L(D;\theta) = \displaystyle{\prod_{i = 1}^m} P(y_i,z_i) =  \pi^{\displaystyle {\sum_{i = 1}^m} z_i}p^{\displaystyle {\sum_{i = 1}^m}z_iy_i}(1-p)^{\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)} \times (1-\pi)^{\displaystyle {\sum_{i = 1}^m}(1-z_i)}q^{\displaystyle {\sum_{i = 1}^m}(1-z_i)y_i}(1-q)^{\displaystyle {\sum_{i = 1}^m}(1-z_i)(1-y_i)}$
为简化运算,取对数形式:

$LL(D;\theta) = \bigg (\displaystyle {\sum_{i = 1}^m} z_i\bigg ) \ln \pi +
\bigg (\displaystyle {\sum_{i = 1}^m}z_iy_i\bigg ) \ln p +
\bigg (\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)\bigg ) \ln (1-p) +
\bigg (\displaystyle {\sum_{i = 1}^m}(1-z_i)\bigg ) \ln (1-\pi) +
\bigg (\displaystyle {\sum_{i = 1}^m}(1-z_i)y_i\bigg ) \ln q +
\bigg (\displaystyle {\sum_{i = 1}^m}(1-z_i)(1-y_i)\bigg ) \ln (1-q)$

$\begin{align}
\frac{\partial LL(D;\theta)}{\partial \theta} &= \begin{bmatrix}
\frac{\partial LL(D;\theta)}{\partial \pi}  \\
\frac{\partial LL(D;\theta)}{\partial p}  \\
\frac{\partial LL(D;\theta)}{\partial q}
\end{bmatrix} \\
&= \begin{bmatrix}
\frac{\displaystyle {\sum_{i = 1}^m} z_i}{\pi} - \frac{\displaystyle{\sum_{i = 1}^m} (1 - z_i)}{1 - \pi}  \\
\frac{\displaystyle {\sum_{i = 1}^m}z_iy_i}{p} - \frac{\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)}{1-p}\\
\frac{\displaystyle {\sum_{i = 1}^m}z_iy_i}{q} - \frac{\displaystyle {\sum_{i = 1}^m}z_i(1-y_i)}{1-q}
\end{bmatrix}
\end{align}$

令$\frac{\partial LL(D;\theta)}{\partial \theta}=0$
得:
$\pi = \frac{ \displaystyle {\sum_{i = 1}^m} z_i}{m}$
$p = \frac{ \displaystyle {\sum_{i = 1}^m} z_iy_i}{m}$
$q = \frac{ \displaystyle {\sum_{i = 1}^m} z_iy_i}{m}$

## 隐变量
上面的例子中,隐变量或者说中间变量$z$往往是未知的,那么我们要怎么进行参数的估计?

按照上面的过程,极大似然法无法进行下去,因为我们并不知道输出的结果$y_i$到底是由B硬币生成的,还是C硬币生成的。

使用极大似然法,在求似然函数的时候,需要知道$y_i$和$z_i$(即样本的生成过程信息),但我们不知道$z_i$到底是多少,所以极大似然法无法进行下去。

### 期望
我们先讲一下期望的概念:

## EM算法的证明

## EM算法的应用-高斯混合聚类
